{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part III: Ensembles and Final Result\n",
    "\n",
    "## AdaBoost\n",
    "\n",
    "Train an AdaBoost classifier using Decision Tree stubs as weak learners. Compare its performance to results obtained in Part II using 10 fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load traning set\n",
    "# note: it can be done by simply loading the data sets. \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_pipeline_file': 'feature_pipeline.pkl',\n",
       " 'labels_pipeline_file': 'labels_pipeline.pkl',\n",
       " 'objstore_path': 'objects',\n",
       " 'processed_data_path': 'processed_data',\n",
       " 'raw_data_csv': 'KaggleV2-May-2016.csv',\n",
       " 'raw_data_path': 'data',\n",
       " 'test_csv': 'test_set.csv',\n",
       " 'train_csv': 'train_set.csv'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import proj2_lib.util as utils\n",
    "\n",
    "utils.file_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90526, 101)\n",
      "(90526,)\n"
     ]
    }
   ],
   "source": [
    "file_config = utils.file_config\n",
    "import proj2_lib.preprocess as preprocess\n",
    "train_X, train_y = preprocess.load_train_data(config=file_config)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AdaBoost code goes here\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth =1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf_fitted = ada_clf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X,y,clf, show_accuracy=True, show_AUC=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "\n",
    "    accuracy_scores = cross_val_score(clf, X, y, \n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "    \n",
    "    \n",
    "    AUC_scores = cross_val_score(clf, X, y, \n",
    "                        scoring=\"roc_auc\", cv=10)\n",
    "    \n",
    "    y_pred=clf.predict(X)   \n",
    "    \n",
    "    print (\"Fitted model:\")\n",
    "    print (clf,\"\\n\")\n",
    "    if show_accuracy:\n",
    "        print (\"Accuracy:\")\n",
    "        print (accuracy_scores,\"\\n\")\n",
    "        print (\"Mean Accuracy\")\n",
    "        print (accuracy_scores.mean(), \"\\n\")\n",
    "        \n",
    "    if show_AUC:\n",
    "        print (\"AUC:\")\n",
    "        print (AUC_scores,\"\\n\")        \n",
    "        print (\"Mean AUC\")\n",
    "        print (AUC_scores.mean(), \"\\n\")        \n",
    "        \n",
    "    if show_classification_report:\n",
    "        print (\"Classification report\")\n",
    "        print (metrics.classification_report(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print (\"Confusion matrix\")\n",
    "        print (metrics.confusion_matrix(y,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted model:\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=0.5, n_estimators=200, random_state=None) \n",
      "\n",
      "Accuracy:\n",
      "[ 0.79863029  0.79642108  0.79763614  0.79851983  0.79818845  0.79807799\n",
      "  0.79739284  0.79606717  0.79783473  0.79772426] \n",
      "\n",
      "Mean Accuracy\n",
      "0.797649276693 \n",
      "\n",
      "AUC:\n",
      "[ 0.72792921  0.72593463  0.72843011  0.73287909  0.7216347   0.73067697\n",
      "  0.72817761  0.72339046  0.73631401  0.72340417] \n",
      "\n",
      "Mean AUC\n",
      "0.727877096994 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.80      1.00      0.89     72246\n",
      "          1       0.48      0.01      0.02     18280\n",
      "\n",
      "avg / total       0.73      0.80      0.71     90526\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[72060   186]\n",
      " [18111   169]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost   cv=10\n",
    "measure_performance(train_X,train_y,ada_clf_fitted, show_classification_report=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance_1fold(X,y,clf, show_accuracy=True, show_AUC=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "# k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more\n",
    "    accuracy_scores = cross_val_score(clf, X, y, \n",
    "                        scoring=\"accuracy\", cv=2) # cv=10\n",
    "    \n",
    "    \n",
    "    AUC_scores = cross_val_score(clf, X, y, \n",
    "                        scoring=\"roc_auc\", cv=2) #  cv=10\n",
    "    \n",
    "    y_pred=clf.predict(X)   \n",
    "    \n",
    "    print (\"Fitted model:\")\n",
    "    print (clf,\"\\n\")\n",
    "    if show_accuracy:\n",
    "        print (\"Accuracy:\")\n",
    "        print (accuracy_scores,\"\\n\")\n",
    "        print (\"Mean Accuracy\")\n",
    "        print (accuracy_scores.mean(), \"\\n\")\n",
    "        \n",
    "    if show_AUC:\n",
    "        print (\"AUC:\")\n",
    "        print (AUC_scores,\"\\n\")        \n",
    "        print (\"Mean AUC\")\n",
    "        print (AUC_scores.mean(), \"\\n\")        \n",
    "        \n",
    "    if show_classification_report:\n",
    "        print (\"Classification report\")\n",
    "        print (metrics.classification_report(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print (\"Confusion matrix\")\n",
    "        print (metrics.confusion_matrix(y,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted model:\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=0.5, n_estimators=200, random_state=None) \n",
      "\n",
      "Accuracy:\n",
      "[ 0.79771557  0.7972958 ] \n",
      "\n",
      "Mean Accuracy\n",
      "0.797505688973 \n",
      "\n",
      "AUC:\n",
      "[ 0.72558335  0.72770482] \n",
      "\n",
      "Mean AUC\n",
      "0.726644083359 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.80      1.00      0.89     72246\n",
      "          1       0.48      0.01      0.02     18280\n",
      "\n",
      "avg / total       0.73      0.80      0.71     90526\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[72060   186]\n",
      " [18111   169]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost cv=2\n",
    "measure_performance_1fold(train_X,train_y,ada_clf_fitted, show_classification_report=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part two we get mean AUC of 0.581839502662, 0.693280593178 , 0.667313327537 for decision tree, random forest and liner SVM using 10 fold CV, respectivly. \n",
    "Here we get an mean AUC of 0.727877096994 for CV=10 and AUC of 0.726644083359 for CV=2 (just 1 train and 1 validation set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "Choose a set of 5 or so classifiers. Write a function that trains an ensemble using stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train part3 set:\n",
      "No     0.798068\n",
      "Yes    0.201932\n",
      "Name: No-show, dtype: float64\n",
      "validation set:\n",
      "No     0.798071\n",
      "Yes    0.201929\n",
      "Name: No-show, dtype: float64\n",
      "90526\n",
      "63368\n",
      "27158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>SMS_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15544</th>\n",
       "      <td>3.469758e+11</td>\n",
       "      <td>5624436</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-26 16:02:13</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>70.0</td>\n",
       "      <td>SANTO ANTÃ?NIO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>2.957690e+12</td>\n",
       "      <td>5767809</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-06-03 07:06:41</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>73.0</td>\n",
       "      <td>ROMÃ?O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85469</th>\n",
       "      <td>3.561431e+11</td>\n",
       "      <td>5703318</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-05-16 13:46:33</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>53.0</td>\n",
       "      <td>SANTA MARTHA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81643</th>\n",
       "      <td>8.243390e+13</td>\n",
       "      <td>5692846</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-05-12 16:28:47</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>34.0</td>\n",
       "      <td>SANTO ANDRÃ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>4.476215e+12</td>\n",
       "      <td>5539468</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-01 15:01:22</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>CONSOLAÃ?Ã?O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PatientId  AppointmentID Gender        ScheduledDay AppointmentDay  \\\n",
       "15544  3.469758e+11        5624436      F 2016-04-26 16:02:13     2016-05-12   \n",
       "4267   2.957690e+12        5767809      F 2016-06-03 07:06:41     2016-06-07   \n",
       "85469  3.561431e+11        5703318      F 2016-05-16 13:46:33     2016-05-17   \n",
       "81643  8.243390e+13        5692846      F 2016-05-12 16:28:47     2016-05-13   \n",
       "226    4.476215e+12        5539468      F 2016-04-01 15:01:22     2016-04-29   \n",
       "\n",
       "        Age   Neighbourhood  Scholarship  Hypertension  Diabetes  Alcoholism  \\\n",
       "15544  70.0  SANTO ANTÃ?NIO            0             0         0           0   \n",
       "4267   73.0          ROMÃ?O            0             1         1           0   \n",
       "85469  53.0    SANTA MARTHA            1             0         0           0   \n",
       "81643  34.0    SANTO ANDRÃ?            1             0         0           0   \n",
       "226    15.0    CONSOLAÃ?Ã?O            0             0         0           0   \n",
       "\n",
       "       Handicap  SMS_received  \n",
       "15544         0             1  \n",
       "4267          0             0  \n",
       "85469         1             0  \n",
       "81643         0             0  \n",
       "226           0             1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROCESSED_DATA_DIR = 'processed_data'\n",
    "clean_df = pd.read_csv(PROCESSED_DATA_DIR + \"/train_set.csv\", parse_dates=['ScheduledDay','AppointmentDay'],\n",
    "                      dtype={'Age': np.float64}, encoding='latin-1')\n",
    "clean_df.head()\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=1234)\n",
    "for train_part3_index, validation_index in split.split(clean_df, clean_df['No-show']):\n",
    "    train_PIII_set = clean_df.iloc[train_part3_index]\n",
    "    validation_set = clean_df.iloc[validation_index]\n",
    "\n",
    "# check class proportions on train and test sets to make sure \n",
    "# properly stratified\n",
    "print(\"Train part3 set:\")\n",
    "print(train_PIII_set['No-show'].value_counts() / len(train_PIII_set))\n",
    "\n",
    "print(\"validation set:\")\n",
    "print(validation_set['No-show'].value_counts() / len(validation_set))\n",
    "print(len(clean_df))\n",
    "print(len(train_PIII_set))\n",
    "print(len(validation_set))\n",
    "\n",
    "# save train and test sets as csvs\n",
    "#train_PIII_set.to_csv(PROCESSED_DATA_DIR + '/train_PIII_set.csv', index=False)\n",
    "#validation_set.to_csv(PROCESSED_DATA_DIR + '/validation_set.csv', index=False)\n",
    "\n",
    "train_PIII_set_labels = train_PIII_set['No-show'].copy()\n",
    "train_PIII_set = train_PIII_set.drop('No-show', axis=1)\n",
    "train_PIII_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_pipeline_file': 'feature_pipeline.pkl',\n",
       " 'labels_pipeline_file': 'labels_pipeline.pkl',\n",
       " 'objstore_path': 'objects',\n",
       " 'processed_data_path': 'processed_data',\n",
       " 'raw_data_csv': 'train_set.csv',\n",
       " 'raw_data_path': 'processed_data',\n",
       " 'test_csv': 'validation_set.csv',\n",
       " 'train_csv': 'train_p3_set.csv'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edit the config file to split the traing set into new training (train_p3_set) set \n",
    "# and new test set (validation set)\n",
    "new_config = utils.file_config.copy()\n",
    "new_config['test_csv']= 'validation_set.csv'\n",
    "new_config['train_csv']= 'train_p3_set.csv'\n",
    "new_config['raw_data_csv']= 'train_set.csv'\n",
    "new_config['raw_data_path']= 'processed_data'\n",
    "new_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN THIS STEP ONCE (switch this to True to run it)\n",
    "RUN_MAKE_TRAIN_TEST_FILES = False\n",
    "if RUN_MAKE_TRAIN_TEST_FILES:\n",
    "    utils.make_train_test_sets(config=new_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import proj2_lib.preprocess as preprocess\n",
    "\n",
    "# ONLY NEED TO RUN THIS STEP ONCE\n",
    "RUN_FIT_PREPROCESSING = False\n",
    "if RUN_FIT_PREPROCESSING:\n",
    "    preprocess.fit_save_pipelines(config=new_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70526, 101)\n",
      "(70526,)\n"
     ]
    }
   ],
   "source": [
    "# Note : the test set here is validation set\n",
    "train_X, train_y = preprocess.load_train_data(config=new_config)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "#test_X, test_y = preprocess.load_test_data(config=new_config)\n",
    "#print(test_X.shape)\n",
    "#print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_stack_ensemble(X, y):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # create train/validation sets\n",
    "    # using StratifiedShuffleSplit\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2 , random_state=1234)\n",
    "    data_set=pd.DataFrame(X.copy())\n",
    "    data_set['label']=y.copy().ravel() \n",
    "    \n",
    "    for train_index, val_index in split.split(data_set, data_set[\"label\"]):\n",
    "        train_p3_set = data_set.iloc[train_index]\n",
    "        val_p3_set = data_set.iloc[val_index]\n",
    "\n",
    "    train_p3_y = np.array(pd.DataFrame(train_p3_set['label'].copy(), columns=[\"label\"])).ravel()\n",
    "    train_p3_X = np.array(train_p3_set.drop('label', axis=1))\n",
    "\n",
    "    val_p3_y = np.array(pd.DataFrame(val_p3_set['label'].copy(), columns=[\"label\"])).ravel()\n",
    "    val_p3_X = np.array(val_p3_set.drop('label', axis=1))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # train classifiers in ensemble using train set\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier    \n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    # \"Decision Tree\", \"Random Forest\", \"Linear SVM\", \"AdaBoost\", \"Nearest Neighbors\" \n",
    "    # \"Gaussian Process\",\"Neural Net\", \"Naive Bayes\", \"QDA\"\n",
    "\n",
    "    classifiers = [DecisionTreeClassifier(), RandomForestClassifier(),LinearSVC(), AdaBoostClassifier(), KNeighborsClassifier(n_neighbors=7)]\n",
    "\n",
    "    \n",
    "    clf1 = DecisionTreeClassifier()\n",
    "    clf1_fitted = clf1.fit(train_p3_X, train_p3_y)\n",
    "\n",
    "    clf2 = RandomForestClassifier()\n",
    "    clf2_fitted = clf2.fit(train_p3_X, train_p3_y)\n",
    "    \n",
    "    clf3 = LinearSVC()\n",
    "    clf3_fitted = clf3.fit(train_p3_X, train_p3_y)\n",
    "\n",
    "    clf4 = AdaBoostClassifier()\n",
    "    clf4_fitted = clf4.fit(train_p3_X, train_p3_y)    \n",
    "    \n",
    "    clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "    clf5_fitted = clf5.fit(train_p3_X, train_p3_y)        \n",
    "\n",
    "    \n",
    "    level2_feature_matrix=np.full((val_p3_X.shape[0],5), 0.0)\n",
    "    count = 0\n",
    "    # iterate over classifiers\n",
    "    for clf in (clf1_fitted, clf2_fitted, clf3_fitted, clf4_fitted, clf4_fitted):\n",
    "        \n",
    "    # create new feature matrix for validation\n",
    "    # set by getting predictions from the ensemble\n",
    "    # classifiers            \n",
    "        level2_feature_matrix[:,count] = clf.predict(val_p3_X)\n",
    "        count+=1\n",
    "      \n",
    "    # train logistic regression classifier on\n",
    "    # new feature matrix\n",
    "    LR = LogisticRegression()\n",
    "    LR_fitted = LR.fit(level2_feature_matrix, val_p3_y)\n",
    "    \n",
    "    \n",
    "    # return all trained classifiers\n",
    "    return (clf1_fitted,clf2_fitted,clf3_fitted,clf4_fitted,clf5_fitted,LR_fitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class StackingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        \n",
    "        return None \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        self.clf1_, self.clf2_ , self.clf3_, self.clf4_, self.clf5_, self.LR_ = build_stack_ensemble(X, y)        \n",
    "\n",
    "        return self\n",
    "        # Fit\n",
    "        #super(Stack_Ensemble_Classifier, self).fit(X, y)  \n",
    "        #return self      \n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        check_is_fitted(self, ['clf1_', 'clf2_', 'clf3_', 'clf4_', 'clf5_', 'LR_'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        level2_feature_matrix=np.full((X.shape[0],5), 0.0)\n",
    "        count=0\n",
    "        for clf in (self.clf1_, self.clf2_ , self.clf3_, self.clf4_,self.clf5_):\n",
    "            level2_feature_matrix[:,count]=clf.predict(X)\n",
    "            count+=1\n",
    "        \n",
    "        return self.LR_.predict(level2_feature_matrix)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        f = self.decision_function(X)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted model:\n",
      "StackingClassifier() \n",
      "\n",
      "Accuracy:\n",
      "[ 0.7979365   0.79696441] \n",
      "\n",
      "Mean Accuracy\n",
      "0.797450456223 \n",
      "\n",
      "AUC:\n",
      "[ 0.51894196  0.51860314] \n",
      "\n",
      "Mean AUC\n",
      "0.518772549006 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.83      1.00      0.91     72246\n",
      "          1       0.93      0.22      0.35     18280\n",
      "\n",
      "avg / total       0.85      0.84      0.79     90526\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[71961   285]\n",
      " [14349  3931]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "stack_clf = StackingClassifier()\n",
    "stack_clf_fitted = stack_clf.fit(train_X,train_y)\n",
    "#roc_scores = cross_val_score(stack_clf, train_X,train_y, scoring=\"roc_auc\", cv=10)\n",
    "measure_performance_1fold(train_X,train_y,stack_clf_fitted, show_classification_report=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10-fold cross validation to measure performance of your stacked classifier. See Part II solution to see how to roll your own sklearn classifier along with http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result\n",
    "\n",
    "Choose a single model based on all previous project steps. Train this model on the complete training dataset and measure it's performance on the held out test set.\n",
    "\n",
    "Compare to the 10-fold CV estimate you got previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final result goes here\n",
    "\n",
    "# AdaBoost trained on all training dataset\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth =1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf_fitted = ada_clf.fit(train_X,train_y)\n",
    "#measure_performance(train_X,train_y,ada_clf_fitted, show_classification_report=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 101)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "file_config = utils.file_config\n",
    "import proj2_lib.preprocess as preprocess\n",
    "test_X, test_y = preprocess.load_test_data(config=file_config)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted model:\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=0.5, n_estimators=200, random_state=None) \n",
      "\n",
      "Accuracy:\n",
      "[ 0.79610195  0.799       0.797       0.7975      0.796       0.7945\n",
      "  0.7975      0.7985      0.796       0.79789895] \n",
      "\n",
      "Mean Accuracy\n",
      "0.79700008985 \n",
      "\n",
      "AUC:\n",
      "[ 0.71969333  0.71786908  0.71090319  0.72948848  0.72423168  0.72437902\n",
      "  0.71775664  0.72437204  0.74670898  0.7442785 ] \n",
      "\n",
      "Mean AUC\n",
      "0.72596809356 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.80      0.99      0.89     15961\n",
      "          1       0.49      0.02      0.04      4039\n",
      "\n",
      "avg / total       0.74      0.80      0.72     20000\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[15881    80]\n",
      " [ 3961    78]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test using test dataset\n",
    "ada_clf_fitted = ada_clf.fit(test_X,test_y)\n",
    "measure_performance(test_X,test_y,ada_clf_fitted, show_classification_report=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
